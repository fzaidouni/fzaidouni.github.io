---
title: "Unified Graph based Multi-Cue Feature Fusion for Robust Visual Tracking"
collection: publications
permalink: /publication/2018-07-ugf
excerpt: 'A novel tracking architecture for visual tracking using multiple feature graph diffusion and adaptive environment adaptation.'
date: 2018-08-05
venue: 'IEEE Transactions on Cybernetics'
paperurl: ''
citation: 'Paper under review for IEEE Transactions on Cybernetics'
---
Visual Tracking is a complex problem due to unconstrained appearance variations and dynamic environment. Extraction of complementary information from the object environment via. multiple features and adaption to target's appearance variations are the key problems of this work. To this end, we propose a robust object tracking framework based on Unified Graph Fusion (UGF) of multi-cue to adapt to the object's appearance. The proposed cross diffusion not only suppresses the individual feature deficiencies but also extracts the complementary information from multi-cue, to tackle object deformations and partial occlusion. Robustness of the unified feature enables the random forest classifier to precisely distinguish the foreground from the background, adding resilience to background clutter. In addition, we present a novel kernel-based adaptation strategy using outlier detection and a transductive reliability metric for updation of the appearance model towards illumination, rotation and scale variations. Both qualitative and quantitative analysis on 20 benchmark video sequences shows that the proposed UGF tracker performs favourably against 15 other state-of-the-art trackers under various object tracking challenges.

The UGF Tracker is able to address the limitations of existing state-of-the-art trackers to a great extent. While, generative trackers like ASLA, FRAG, IVT, DFT, and MTT were not very robust against background clutters and shape information, discriminative trackers, like MIL, CT and, STRUCK tracker were unable to tackle target rotational and deformation challenges. IVT was not able to handle the dynamic appearance variations of target and DFT was not able to cater to large pose variations. KCF tracker used only a single cue for tracking and was not able to overcome variations in scale, whereas MTT was unable to sustain deformations. SCM and MEEM showed resistance to background clutters and illumination variations but were unable to re-detect the target once the tracker drifted. CCOT showed performance almost at-par with UGF but was not comparatively slower than the proposed algorithm.

In sum, UGF shows superior performance against existing state-of-the-art trackers, in both object overlap and precision threshold with highest average F-Measure, lowest average CLE and favourable average computational demands on 20 benchmark dataset.
<!-- [Download paper here](http://academicpages.github.io/files/paper2.pdf) -->

<!-- Recommended citation: Your Name, You. (2010). "Paper Title Number 2." <i>Journal 1</i>. 1(2). -->
